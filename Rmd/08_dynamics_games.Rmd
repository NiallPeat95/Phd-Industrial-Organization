---
title: "Dynamic Games"
author: "Matteo Courthoud"
type: book
weight: 8
date: 2021-10-29
bibliography: references.bib
link-citations: true
output: 
  html_notebook: 
    toc: true
    toc_depth: 2
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    toc_collapsed: true
    keep_md: true
  md_document:
    variant: markdown_mmd
    preserve_yaml: true
  ioslides_presentation:
    widescreen: true
    smaller: true
    transition: 0
    slide_level: 3
editor_options: 
  markdown: 
    wrap: 72
---





## Model

### Intro

Setting: agents making **strategic decisions** in **dynamic environments**. 

- Entry and exit: @collard2013demand
- Sunk costs: @ryan2012costs
- Innovation: @igami2017estimating
  - (or whatever changes in response to investment)
- Learning-by-doing
- Switching costs
- Stockpiling: @hendel2006measuring



### Simple Example

Lousely taken from @ericson1995markov

- Builds on @maskin1988theory, @maskin1988theory, @maskin1987theory

- Firms invest to increase the future quality of their product

- State $s_{it}$: quality of product $i$ in period $t$

- Per period profits
  $$
  \pi ( s_{it}, s_{-it}, ; \theta^\pi)
  $$
  where

  - $s_{-it}$: state vector of all other firms in period $t$
  - $\theta^\pi$: parameters that govern static profits

- We can micro-fund profits with some demand and supply functions



### Dynamic Decisions

In each period firms have 3 choices (in order)

1. If entrant, $e_{it}$: whether to enter the market or not

2. If incumbent, $d_{it}$: whether to exit the market or not

3. If incumbent, $a_{it}$: investment

   - Influences your state transition probability $f$
     $$
     s_{i, t+1} = f(s_{it}, a_{it}, \epsilon_{it} ; \theta^f)
     $$
     where

     - $\epsilon_{it}$: shock that is not known to the firm when making the decision
       - it does not need to be there
     - $\theta^f$: parameters that govern state transitions

   - Example of transition
     $$
     s_{i, t+1} = \delta s_{it} + a_{it} + \epsilon_{it}
     $$
     I.e. depreciation of capital + investment and noise



### Value Function

Belman Equation incumbent $i$ at time $t$
$$
\begin{aligned}
V (s_{i t}, s_{-i t} ; \theta) = & \pi(s_{i t}, s_{-i t} ; \theta^{\pi}) + \max_{d_{i} \in \lbrace 0,1 \rbrace} 
\Bigg\lbrace
\begin{array}{c}
\beta \phi \ ; \newline
\max _{a_{i t} \geq 0} \Big\lbrace - a_{i t} + \beta \mathbb E \Big[V (s_{i, t+1}, s_{-i, t+1} \ ; ] \theta) \Big| s_{i t}, s_{-i t}, a_{i t} \Big] \Big\rbrace 
\end{array}
\Bigg\rbrace
\end{aligned}
$$
where

- $\beta \in (0,1)$: discount factor
- $\phi$: exit scrap value
- $a_{it} \in \mathbb R_+$: investment decision, in dollars
- $d_{it} \in \lbrace 0,1 \rbrace$: exit decision
- The expectation $\mathbb E$ is over
  - The shocks $\epsilon_{it}$
  - Rivals future states $s_{-i,t+1}$



### Entry

We can also incorporate endogenous entry.

- One or more **potential entrants** exist outside the market
- They can pay an entry cost $\kappa$ and enter the market at a quality state $\bar s$

Value function
$$
V^{\text {e}} (s_{i t}, s_{-i t} ; \theta) = \max_{e \in \lbrace 0,1 \rbrace }
\Bigg\lbrace
\begin{array}{c}
0 \ ; \newline
-\kappa + \beta \mathbb E \Big[ V(\bar s, s_{-i, t+1} ; \theta) \Big| s_{t} \Big]
\end{array}
\Bigg\rbrace
$$
where

- $e \in \lbrace 0,1 \rbrace$: entry decision
- $\kappa$: entry cost

Do we observe potential entrants?

- @igami2017estimating: tech industry announce their entry
- Critique: not really potential entrants, they are half-way inside





### Equilibrium

Equillibrium notion: **Markow Perfect Equilibrium** [@maskin1988theory]

- A set value, policy functions and transition probabilities
  $$
  \Big \lbrace \ V(\cdot), \ V^{e n t}(\cdot), \ d(\cdot), \ a(\cdot), \ e(\cdot), \ f(s_{-i, t+1} | s_{t}) \ \Big \rbrace
  $$
  such that

  1. $V(\cdot), \ V^{e n t}(\cdot), \ d(\cdot), \ a(\cdot), \ e(\cdot)$ solve their respective equations *given* $f(s_{-i, t+1} | s_{t})$
  2. the transition probabilities $f(s_{-i, t+1} | s_{t})$ are generated by the strategies $d(\cdot), \ a(\cdot), \ e(\cdot)$

What is it basically?

- Nash Equilibrium in the policy functions
- What are we ruling out?
  - Strategies that depend on longer histories
  - E.g. "has anyone ever cheated in a cartel?"



### Solving the model

Numerically!

1. Given parameter values $\theta$
2. Start with a guess for the value and policy functions
3. They will imply some transition probabilities
4. That will imply some new policies and so on...
5. ... until what?



**Issues**

- No guarantee of convergence
  - @doraszelski2010computable: prove existence of MPE with random costs/scrap values
  - The BR iteration can never find mixed-strategy equilibria
- Multiple equilibria issues
- Curse of dimensionality (computational issue, not conceptual)



### Multiple Equilibria

- @besanko2010learning and @borkovsky2010user: homotopy method 
  - can find some equilibria
  - not all
  - complicated to implement
- @iskhakov2017endogenous: grid method
  - can find all equilibria
  - but for very specific class of dynamic games
  - must always proceed "forward" 
    - e.g. either entry or exit but not both
- @pesendorfer2010sequential: the BR iteration cannot find all possible equilibria, because some equilibria are not Lyapunov-stable, which means you cannot find one unless you start your numerical search from the exact solution
- @su2012constrained and @egesdal2015estimating: show this point numerically, by using their proposed Mathematical Programming with Equilibrium Constraints (MPEC) approach.



### Curse of Dimensionality

Two potential solutions:

1. **Computational**: approximate the equilibrium
   - @doraszelski2019dynamic: games with random moves
   - @farias2012approximate: solve the global problem approximately
2. **Conceptual**: define another game
   - @weintraub2008markov: oblivious equilibrium
   - @pakes2001stochastic and @fershtman2012dynamic: experience-based equilibrium
   - @doraszelski2012avoiding: games in continuous time



## Estimation - Bajari, Benkard, Levin (2008)

### Methods

We want to estimate 3 sets of **parameters**:

- $\theta^\pi$: parameterizes period profit function $\pi()$
- $\theta^f$: parameterizes state transition function $f()$
- $\theta^{ddc}$: scrap value $\phi$ and entry cost $\kappa$

Generally 2 **approaches**

1. Full solution
   - Impractical
2. @hotz1993conditional CCP inversion
   - @aguirregabiria2007sequential
   - @bajari2007estimating
   - @pakes2007simple
   - @pesendorfer2008asymptotic



### BBL: First Stage

First stage: estimate the policy functions (CCP) non-parametrically

- Directly retrievable from data
  - Entry decisions $\hat e (s_{i t}, s_{-i t})$
  - Exit decisions $\hat d (s_{i t}, s_{-i t})$
  - Investment decisions $\hat a (s_{i t}, s_{-i t})$
  - Transition probabilities $\hat f (s_{i t}, s_{-i t} ; \theta^f)$
- Conditional on having enough data
  - **Note**: need to estimate choice probabilities, conditional on each state
  - Problem with many states but especially with many players
    - Curse of dimensionality
  - Problem especially for transition probabilities: state $\times$ state
- Important to do it non-parametrically: parametric assumptions would contradict the model for the estimation of value/polify functions



### BBL: Second Stage

We now have the policy functions, CCPs and state transition probabilities

- We can use them together to simulate **histories**
- If we have a candidate value of $\theta^\pi$, we can compute static payoffs
- Simulated history + static payoffs = simualted value function
- We can average over may simulated value functions to get an **expected value function**

What is the objective function?

- Potentially many options
- We want parameters that give firms the highest values, given those strategies (CCPs)



### In Practice

Take a parameter $\theta$.

For many simulations do:

- Initialize firms value to zero
- Fot $t=0 ... \infty$ do
  - For each state do:
    - For each firm do:
      - Compute static profits $\pi(s_{i t}, s_{-i t} ; \theta^{\pi})$
      - Compute firms actions using $\hat a (s_{i t}, s_{-i t})$ and $\hat d (s_{i t}, s_{-i t})$
      - If firm exits, $\hat d = 0$, end
      - If not, $\hat d = 1$, subtract $a_{i,t}$ from profits 
      - Use $\hat f (s_{i t}, s_{-i t} ; \theta^f)$ to *simulate* next state for firm $i$
      - Add discounted profits to the value function $\beta^t \pi(s_{i t}, s_{-i t} ; \theta^{\pi})$
    - Use the next state, $(s_{i t+1}, s_{-i t+1})$ as current state for the next iteration

Then average all the value functions together to obtain an **expected value function** $\mathbb E \Big[ V (s_{i t}, s_{-i t} ; \theta) \Big]$

- **Note**: advantage of simulations: can be parallelized



### Objective Function

**Idea**

- If the observed choices $\hat a (s_{i t}, s_{-i t})$ and $\hat d (s_{i t}, s_{-i t})$ are optimal, 

  - All other choices $\tilde a (s_{i t}, s_{-i t})$ and $\tilde d (s_{i t}, s_{-i t})$ 

  - At the true parameters $\theta$

  - Should give a lower expected value
    $$
    \mathbb E \Big[ \tilde V (s_{i t}, s_{-i t} ; \theta) \Big] \leq \mathbb E \Big[ V (s_{i t}, s_{-i t} ; \theta) \Big]
    $$
    

- So which are the true parameters?

  - Those for which any deviation from the policy yields a lowe value

  - **Objective function**: minimize the violations
    $$
    \hat{\theta}= \arg \min_{\theta} \sum_{\left(s_{i t}, s_{-i t}\right)} \sum_{(\tilde{a}, \tilde{d})} \Bigg[\min \bigg\lbrace \mathbb E \Big[ \tilde V (s_{i t}, s_{-i t} ; \theta) \Big] - \mathbb E \Big[ V (s_{i t}, s_{-i t} ; \theta) \Big], 0 \bigg\rbrace \Bigg]^{2}
    $$
    



### Comments

**Objective function**: minimization of the violations for any other policy
$$
\hat{\theta}= \arg \min_{\theta} \sum_{\left(s_{i t}, s_{-i t}\right)} \sum_{(\tilde{a}, \tilde{d})} \Bigg[\min \bigg\lbrace \mathbb E \Big[ \tilde V (s_{i t}, s_{-i t} ; \theta) \Big] - \mathbb E \Big[ V (s_{i t}, s_{-i t} ; \theta) \Big], 0 \bigg\rbrace \Bigg]^{2}
$$

- $\min \lbrace g(\cdot), 0  \rbrace$ to pick only the violations
  - If inequality is respected, we can ignore
  - Doesn't matter by how much you respect the inequality
- Which perturbation $\tilde a (s_{i t}, s_{-i t})$ and $\tilde d (s_{i t}, s_{-i t})$ ?
  - In principle, any perturbation is ok
  - But in practice, if we perturbe it too much, we can go too far off
  - Tip 1: start with *very small perturbations*
  - Tip 2: use perturbation that sensibly affect the dynamics
    - E.g. exiting less in states with already low exit probability is probably irrelevant



### Problems

1. Computational **curse of dimensionality** is gone (in the state space)
   - But we have a curse of dimensionality in data
   - Need a lot of markets because **now 1 market is 1 observation**
2. **Multiple equilibria**??
   - We are basically assuming it away
   - Estimating the CCPs in the first stage we assume that is the equilibrium tht is played in all markets at all times
   - To run counterfactuals, we still need to solve the model
3. Unobserved heterogeneity
   - @kasahara2009nonparametric: how to identify the (minimum) number of unobserved types
   - @arcidiacono2011conditional: how to use an EM algorithm for the 1st stage estimation with unobserved types, conditional on the number of types
   - @berry2021empirical: instrumental variables approach, relying on observed states in the distant past
4. **Non-stationarity**
   - If we have a long time period, something fundamentally might have changed







## References

------------------------------------------------------------------------
