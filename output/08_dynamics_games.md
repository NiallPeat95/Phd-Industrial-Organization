---
author: Matteo Courthoud
bibliography: references.bib
date: 2021-10-29
editor_options:
  markdown:
    wrap: 72
link-citations: true
output:
  html_document:
    keep_md: true
    toc: true
    toc_collapsed: true
    toc_depth: 3
    toc_float: true
  html_notebook:
    toc: true
    toc_depth: 2
  ioslides_presentation:
    slide_level: 3
    smaller: true
    transition: 0
    widescreen: true
  md_document:
    preserve_yaml: true
    variant: markdown_mmd
title: Dynamic Games
type: book
weight: 8
---

## Model

### Intro

Setting: agents making **strategic decisions** in **dynamic
environments**.

-   Entry and exit: Collard-Wexler ([2013](#ref-collard2013demand))
-   Sunk costs: Ryan ([2012](#ref-ryan2012costs))
-   Innovation: Igami ([2017](#ref-igami2017estimating))
    -   (or whatever changes in response to investment)
-   Learning-by-doing
-   Switching costs
-   Stockpiling: Hendel and Nevo ([2006](#ref-hendel2006measuring))

### Simple Example

Lousely taken from Ericson and Pakes ([1995](#ref-ericson1995markov))

-   Builds on Maskin and Tirole ([1988](#ref-maskin1988theory)), Maskin
    and Tirole ([1988](#ref-maskin1988theory)), Maskin and Tirole
    ([1987](#ref-maskin1987theory))

-   Firms invest to increase the future quality of their product

-   State $s_{it}$: quality of product $i$ in period $t$

-   Per period profits $$
    \pi ( s_{it}, s_{-it}, ; \theta^\pi)
    $$ where

    -   $s_{-it}$: state vector of all other firms in period $t$
    -   $\theta^\pi$: parameters that govern static profits

-   We can micro-fund profits with some demand and supply functions

### Dynamic Decisions

In each period firms have 3 choices (in order)

1.  If entrant, $e_{it}$: whether to enter the market or not

2.  If incumbent, $d_{it}$: whether to exit the market or not

3.  If incumbent, $a_{it}$: investment

    -   Influences your state transition probability $f$ $$
        s_{i, t+1} = f(s_{it}, a_{it}, \epsilon_{it} ; \theta^f)
        $$ where

        -   $\epsilon_{it}$: shock that is not known to the firm when
            making the decision
            -   it does not need to be there
        -   $\theta^f$: parameters that govern state transitions

    -   Example of transition $$
        s_{i, t+1} = \delta s_{it} + a_{it} + \epsilon_{it}
        $$ I.e. depreciation of capital + investment and noise

### Value Function

Belman Equation incumbent $i$ at time $t$ $$
\begin{aligned}
V (s_{i t}, s_{-i t} ; \theta) = & \pi(s_{i t}, s_{-i t} ; \theta^{\pi}) + \max_{d_{i} \in \lbrace 0,1 \rbrace} 
\Bigg\lbrace
\begin{array}{c}
\beta \phi \ ; \newline
\max _{a_{i t} \geq 0} \Big\lbrace - a_{i t} + \beta \mathbb E \Big[V (s_{i, t+1}, s_{-i, t+1} \ ; ] \theta) \Big| s_{i t}, s_{-i t}, a_{i t} \Big] \Big\rbrace 
\end{array}
\Bigg\rbrace
\end{aligned}
$$ where

-   $\beta \in (0,1)$: discount factor
-   $\phi$: exit scrap value
-   $a_{it} \in \mathbb R_+$: investment decision, in dollars
-   $d_{it} \in \lbrace 0,1 \rbrace$: exit decision
-   The expectation $\mathbb E$ is over
    -   The shocks $\epsilon_{it}$
    -   Rivals future states $s_{-i,t+1}$

### Entry

We can also incorporate endogenous entry.

-   One or more **potential entrants** exist outside the market
-   They can pay an entry cost $\kappa$ and enter the market at a
    quality state $\bar s$

Value function $$
V^{\text {e}} (s_{i t}, s_{-i t} ; \theta) = \max_{e \in \lbrace 0,1 \rbrace }
\Bigg\lbrace
\begin{array}{c}
0 \ ; \newline
-\kappa + \beta \mathbb E \Big[ V(\bar s, s_{-i, t+1} ; \theta) \Big| s_{t} \Big]
\end{array}
\Bigg\rbrace
$$ where

-   $e \in \lbrace 0,1 \rbrace$: entry decision
-   $\kappa$: entry cost

Do we observe potential entrants?

-   Igami ([2017](#ref-igami2017estimating)): tech industry announce
    their entry
-   Critique: not really potential entrants, they are half-way inside

### Equilibrium

Equillibrium notion: **Markow Perfect Equilibrium** ([Maskin and Tirole
1988](#ref-maskin1988theory))

-   A set value, policy functions and transition probabilities $$
    \Big \lbrace \ V(\cdot), \ V^{e n t}(\cdot), \ d(\cdot), \ a(\cdot), \ e(\cdot), \ f(s_{-i, t+1} | s_{t}) \ \Big \rbrace
    $$ such that

    1.  $V(\cdot), \ V^{e n t}(\cdot), \ d(\cdot), \ a(\cdot), \ e(\cdot)$
        solve their respective equations *given*
        $f(s_{-i, t+1} | s_{t})$
    2.  the transition probabilities $f(s_{-i, t+1} | s_{t})$ are
        generated by the strategies $d(\cdot), \ a(\cdot), \ e(\cdot)$

What is it basically?

-   Nash Equilibrium in the policy functions
-   What are we ruling out?
    -   Strategies that depend on longer histories
    -   E.g. “has anyone ever cheated in a cartel?”

### Solving the model

Numerically!

1.  Given parameter values $\theta$
2.  Start with a guess for the value and policy functions
3.  They will imply some transition probabilities
4.  That will imply some new policies and so on…
5.  … until what?

**Issues**

-   No guarantee of convergence
    -   Doraszelski and Satterthwaite
        ([2010](#ref-doraszelski2010computable)): prove existence of MPE
        with random costs/scrap values
    -   The BR iteration can never find mixed-strategy equilibria
-   Multiple equilibria issues
-   Curse of dimensionality (computational issue, not conceptual)

### Multiple Equilibria

-   Besanko et al. ([2010](#ref-besanko2010learning)) and Borkovsky,
    Doraszelski, and Kryukov ([2010](#ref-borkovsky2010user)): homotopy
    method
    -   can find some equilibria
    -   not all
    -   complicated to implement
-   Iskhakov et al. ([2017](#ref-iskhakov2017endogenous)): grid method
    -   can find all equilibria
    -   but for very specific class of dynamic games
    -   must always proceed “forward”
        -   e.g. either entry or exit but not both
-   Pesendorfer and Schmidt-Dengler
    ([2010](#ref-pesendorfer2010sequential)): the BR iteration cannot
    find all possible equilibria, because some equilibria are not
    Lyapunov-stable, which means you cannot find one unless you start
    your numerical search from the exact solution
-   Su and Judd ([2012](#ref-su2012constrained)) and Egesdal, Lai, and
    Su ([2015](#ref-egesdal2015estimating)): show this point
    numerically, by using their proposed Mathematical Programming with
    Equilibrium Constraints (MPEC) approach.

### Curse of Dimensionality

Two potential solutions:

1.  **Computational**: approximate the equilibrium
    -   Doraszelski and Judd ([2019](#ref-doraszelski2019dynamic)):
        games with random moves
    -   Farias, Saure, and Weintraub
        ([2012](#ref-farias2012approximate)): solve the global problem
        approximately
2.  **Conceptual**: define another game
    -   Weintraub, Benkard, and Van Roy
        ([2008](#ref-weintraub2008markov)): oblivious equilibrium
    -   Pakes and McGuire ([2001](#ref-pakes2001stochastic)) and
        Fershtman and Pakes ([2012](#ref-fershtman2012dynamic)):
        experience-based equilibrium
    -   Doraszelski and Judd ([2012](#ref-doraszelski2012avoiding)):
        games in continuous time

## Estimation - Bajari, Benkard, Levin (2008)

### Methods

We want to estimate 3 sets of **parameters**:

-   $\theta^\pi$: parameterizes period profit function $\pi()$
-   $\theta^f$: parameterizes state transition function $f()$
-   $\theta^{ddc}$: scrap value $\phi$ and entry cost $\kappa$

Generally 2 **approaches**

1.  Full solution
    -   Impractical
2.  Hotz and Miller ([1993](#ref-hotz1993conditional)) CCP inversion
    -   Aguirregabiria and Mira
        ([2007](#ref-aguirregabiria2007sequential))
    -   Bajari, Benkard, and Levin ([2007](#ref-bajari2007estimating))
    -   Pakes, Ostrovsky, and Berry ([2007](#ref-pakes2007simple))
    -   Pesendorfer and Schmidt-Dengler
        ([2008](#ref-pesendorfer2008asymptotic))

### BBL: First Stage

First stage: estimate the policy functions (CCP) non-parametrically

-   Directly retrievable from data
    -   Entry decisions $\hat e (s_{i t}, s_{-i t})$
    -   Exit decisions $\hat d (s_{i t}, s_{-i t})$
    -   Investment decisions $\hat a (s_{i t}, s_{-i t})$
    -   Transition probabilities $\hat f (s_{i t}, s_{-i t} ; \theta^f)$
-   Conditional on having enough data
    -   **Note**: need to estimate choice probabilities, conditional on
        each state
    -   Problem with many states but especially with many players
        -   Curse of dimensionality
    -   Problem especially for transition probabilities: state $\times$
        state
-   Important to do it non-parametrically: parametric assumptions would
    contradict the model for the estimation of value/polify functions

### BBL: Second Stage

We now have the policy functions, CCPs and state transition
probabilities

-   We can use them together to simulate **histories**
-   If we have a candidate value of $\theta^\pi$, we can compute static
    payoffs
-   Simulated history + static payoffs = simualted value function
-   We can average over may simulated value functions to get an
    **expected value function**

What is the objective function?

-   Potentially many options
-   We want parameters that give firms the highest values, given those
    strategies (CCPs)

### In Practice

Take a parameter $\theta$.

For many simulations do:

-   Initialize firms value to zero
-   Fot $t=0 ... \infty$ do
    -   For each state do:
        -   For each firm do:
            -   Compute static profits
                $\pi(s_{i t}, s_{-i t} ; \theta^{\pi})$
            -   Compute firms actions using $\hat a (s_{i t}, s_{-i t})$
                and $\hat d (s_{i t}, s_{-i t})$
            -   If firm exits, $\hat d = 0$, end
            -   If not, $\hat d = 1$, subtract $a_{i,t}$ from profits
            -   Use $\hat f (s_{i t}, s_{-i t} ; \theta^f)$ to
                *simulate* next state for firm $i$
            -   Add discounted profits to the value function
                $\beta^t \pi(s_{i t}, s_{-i t} ; \theta^{\pi})$
        -   Use the next state, $(s_{i t+1}, s_{-i t+1})$ as current
            state for the next iteration

Then average all the value functions together to obtain an **expected
value function** $\mathbb E \Big[ V (s_{i t}, s_{-i t} ; \theta) \Big]$

-   **Note**: advantage of simulations: can be parallelized

### Objective Function

**Idea**

-   If the observed choices $\hat a (s_{i t}, s_{-i t})$ and
    $\hat d (s_{i t}, s_{-i t})$ are optimal,

    -   All other choices $\tilde a (s_{i t}, s_{-i t})$ and
        $\tilde d (s_{i t}, s_{-i t})$

    -   At the true parameters $\theta$

    -   Should give a lower expected value $$
        \mathbb E \Big[ \tilde V (s_{i t}, s_{-i t} ; \theta) \Big] \leq \mathbb E \Big[ V (s_{i t}, s_{-i t} ; \theta) \Big]
        $$

-   So which are the true parameters?

    -   Those for which any deviation from the policy yields a lowe
        value

    -   **Objective function**: minimize the violations $$
        \hat{\theta}= \arg \min_{\theta} \sum_{\left(s_{i t}, s_{-i t}\right)} \sum_{(\tilde{a}, \tilde{d})} \Bigg[\min \bigg\lbrace \mathbb E \Big[ \tilde V (s_{i t}, s_{-i t} ; \theta) \Big] - \mathbb E \Big[ V (s_{i t}, s_{-i t} ; \theta) \Big], 0 \bigg\rbrace \Bigg]^{2}
        $$

### Comments

**Objective function**: minimization of the violations for any other
policy $$
\hat{\theta}= \arg \min_{\theta} \sum_{\left(s_{i t}, s_{-i t}\right)} \sum_{(\tilde{a}, \tilde{d})} \Bigg[\min \bigg\lbrace \mathbb E \Big[ \tilde V (s_{i t}, s_{-i t} ; \theta) \Big] - \mathbb E \Big[ V (s_{i t}, s_{-i t} ; \theta) \Big], 0 \bigg\rbrace \Bigg]^{2}
$$

-   $\min \lbrace g(\cdot), 0 \rbrace$ to pick only the violations
    -   If inequality is respected, we can ignore
    -   Doesn’t matter by how much you respect the inequality
-   Which perturbation $\tilde a (s_{i t}, s_{-i t})$ and
    $\tilde d (s_{i t}, s_{-i t})$ ?
    -   In principle, any perturbation is ok
    -   But in practice, if we perturbe it too much, we can go too far
        off
    -   Tip 1: start with *very small perturbations*
    -   Tip 2: use perturbation that sensibly affect the dynamics
        -   E.g. exiting less in states with already low exit
            probability is probably irrelevant

### Problems

1.  Computational **curse of dimensionality** is gone (in the state
    space)
    -   But we have a curse of dimensionality in data
    -   Need a lot of markets because **now 1 market is 1 observation**
2.  **Multiple equilibria**??
    -   We are basically assuming it away
    -   Estimating the CCPs in the first stage we assume that is the
        equilibrium tht is played in all markets at all times
    -   To run counterfactuals, we still need to solve the model
3.  Unobserved heterogeneity
    -   Kasahara and Shimotsu ([2009](#ref-kasahara2009nonparametric)):
        how to identify the (minimum) number of unobserved types
    -   Arcidiacono and Miller
        ([2011](#ref-arcidiacono2011conditional)): how to use an EM
        algorithm for the 1st stage estimation with unobserved types,
        conditional on the number of types
    -   Berry and Compiani ([2021](#ref-berry2021empirical)):
        instrumental variables approach, relying on observed states in
        the distant past
4.  **Non-stationarity**
    -   If we have a long time period, something fundamentally might
        have changed

## References

------------------------------------------------------------------------

<div id="refs" class="references csl-bib-body hanging-indent"
markdown="1">

<div id="ref-aguirregabiria2007sequential" class="csl-entry"
markdown="1">

Aguirregabiria, Victor, and Pedro Mira. 2007. “Sequential Estimation of
Dynamic Discrete Games.” *Econometrica* 75 (1): 1–53.

</div>

<div id="ref-arcidiacono2011conditional" class="csl-entry" markdown="1">

Arcidiacono, Peter, and Robert A Miller. 2011. “Conditional Choice
Probability Estimation of Dynamic Discrete Choice Models with Unobserved
Heterogeneity.” *Econometrica* 79 (6): 1823–67.

</div>

<div id="ref-bajari2007estimating" class="csl-entry" markdown="1">

Bajari, Patrick, C Lanier Benkard, and Jonathan Levin. 2007. “Estimating
Dynamic Models of Imperfect Competition.” *Econometrica* 75 (5):
1331–70.

</div>

<div id="ref-berry2021empirical" class="csl-entry" markdown="1">

Berry, Steven T, and Giovanni Compiani. 2021. “Empirical Models of
Industry Dynamics with Endogenous Market Structure.” *Annual Review of
Economics* 13.

</div>

<div id="ref-besanko2010learning" class="csl-entry" markdown="1">

Besanko, David, Ulrich Doraszelski, Yaroslav Kryukov, and Mark
Satterthwaite. 2010. “Learning-by-Doing, Organizational Forgetting, and
Industry Dynamics.” *Econometrica* 78 (2): 453–508.

</div>

<div id="ref-borkovsky2010user" class="csl-entry" markdown="1">

Borkovsky, Ron N, Ulrich Doraszelski, and Yaroslav Kryukov. 2010. “A
User’s Guide to Solving Dynamic Stochastic Games Using the Homotopy
Method.” *Operations Research* 58 (4-part-2): 1116–32.

</div>

<div id="ref-collard2013demand" class="csl-entry" markdown="1">

Collard-Wexler, Allan. 2013. “Demand Fluctuations in the Ready-Mix
Concrete Industry.” *Econometrica* 81 (3): 1003–37.

</div>

<div id="ref-doraszelski2012avoiding" class="csl-entry" markdown="1">

Doraszelski, Ulrich, and Kenneth L Judd. 2012. “Avoiding the Curse of
Dimensionality in Dynamic Stochastic Games.” *Quantitative Economics* 3
(1): 53–93.

</div>

<div id="ref-doraszelski2019dynamic" class="csl-entry" markdown="1">

———. 2019. “Dynamic Stochastic Games with Random Moves.” *Quantitative
Marketing and Economics* 17 (1): 59–79.

</div>

<div id="ref-doraszelski2010computable" class="csl-entry" markdown="1">

Doraszelski, Ulrich, and Mark Satterthwaite. 2010. “Computable
Markov-Perfect Industry Dynamics.” *The RAND Journal of Economics* 41
(2): 215–43.

</div>

<div id="ref-egesdal2015estimating" class="csl-entry" markdown="1">

Egesdal, Michael, Zhenyu Lai, and Che-Lin Su. 2015. “Estimating Dynamic
Discrete-Choice Games of Incomplete Information.” *Quantitative
Economics* 6 (3): 567–97.

</div>

<div id="ref-ericson1995markov" class="csl-entry" markdown="1">

Ericson, Richard, and Ariel Pakes. 1995. “Markov-Perfect Industry
Dynamics: A Framework for Empirical Work.” *The Review of Economic
Studies* 62 (1): 53–82.

</div>

<div id="ref-farias2012approximate" class="csl-entry" markdown="1">

Farias, Vivek, Denis Saure, and Gabriel Y Weintraub. 2012. “An
Approximate Dynamic Programming Approach to Solving Dynamic Oligopoly
Models.” *The RAND Journal of Economics* 43 (2): 253–82.

</div>

<div id="ref-fershtman2012dynamic" class="csl-entry" markdown="1">

Fershtman, Chaim, and Ariel Pakes. 2012. “Dynamic Games with Asymmetric
Information: A Framework for Empirical Work.” *The Quarterly Journal of
Economics* 127 (4): 1611–61.

</div>

<div id="ref-hendel2006measuring" class="csl-entry" markdown="1">

Hendel, Igal, and Aviv Nevo. 2006. “Measuring the Implications of Sales
and Consumer Inventory Behavior.” *Econometrica* 74 (6): 1637–73.

</div>

<div id="ref-hotz1993conditional" class="csl-entry" markdown="1">

Hotz, V Joseph, and Robert A Miller. 1993. “Conditional Choice
Probabilities and the Estimation of Dynamic Models.” *The Review of
Economic Studies* 60 (3): 497–529.

</div>

<div id="ref-igami2017estimating" class="csl-entry" markdown="1">

Igami, Mitsuru. 2017. “Estimating the Innovator’s Dilemma: Structural
Analysis of Creative Destruction in the Hard Disk Drive Industry,
1981–1998.” *Journal of Political Economy* 125 (3): 798–847.

</div>

<div id="ref-iskhakov2017endogenous" class="csl-entry" markdown="1">

Iskhakov, Fedor, Thomas H Jørgensen, John Rust, and Bertel Schjerning.
2017. “The Endogenous Grid Method for Discrete-Continuous Dynamic Choice
Models with (or Without) Taste Shocks.” *Quantitative Economics* 8 (2):
317–65.

</div>

<div id="ref-kasahara2009nonparametric" class="csl-entry" markdown="1">

Kasahara, Hiroyuki, and Katsumi Shimotsu. 2009. “Nonparametric
Identification of Finite Mixture Models of Dynamic Discrete Choices.”
*Econometrica* 77 (1): 135–75.

</div>

<div id="ref-maskin1987theory" class="csl-entry" markdown="1">

Maskin, Eric, and Jean Tirole. 1987. “A Theory of Dynamic Oligopoly,
III: Cournot Competition.” *European Economic Review* 31 (4): 947–68.

</div>

<div id="ref-maskin1988theory" class="csl-entry" markdown="1">

———. 1988. “A Theory of Dynamic Oligopoly, II: Price Competition, Kinked
Demand Curves, and Edgeworth Cycles.” *Econometrica: Journal of the
Econometric Society*, 571–99.

</div>

<div id="ref-pakes2001stochastic" class="csl-entry" markdown="1">

Pakes, Ariel, and Paul McGuire. 2001. “Stochastic Algorithms, Symmetric
Markov Perfect Equilibrium, and the ‘Curse’of Dimensionality.”
*Econometrica* 69 (5): 1261–81.

</div>

<div id="ref-pakes2007simple" class="csl-entry" markdown="1">

Pakes, Ariel, Michael Ostrovsky, and Steven Berry. 2007. “Simple
Estimators for the Parameters of Discrete Dynamic Games (with Entry/Exit
Examples).” *The RAND Journal of Economics* 38 (2): 373–99.

</div>

<div id="ref-pesendorfer2008asymptotic" class="csl-entry" markdown="1">

Pesendorfer, Martin, and Philipp Schmidt-Dengler. 2008. “Asymptotic
Least Squares Estimators for Dynamic Games.” *The Review of Economic
Studies* 75 (3): 901–28.

</div>

<div id="ref-pesendorfer2010sequential" class="csl-entry" markdown="1">

———. 2010. “Sequential Estimation of Dynamic Discrete Games: A Comment.”
*Econometrica* 78 (2): 833–42.

</div>

<div id="ref-ryan2012costs" class="csl-entry" markdown="1">

Ryan, Stephen P. 2012. “The Costs of Environmental Regulation in a
Concentrated Industry.” *Econometrica* 80 (3): 1019–61.

</div>

<div id="ref-su2012constrained" class="csl-entry" markdown="1">

Su, Che-Lin, and Kenneth L Judd. 2012. “Constrained Optimization
Approaches to Estimation of Structural Models.” *Econometrica* 80 (5):
2213–30.

</div>

<div id="ref-weintraub2008markov" class="csl-entry" markdown="1">

Weintraub, Gabriel Y, C Lanier Benkard, and Benjamin Van Roy. 2008.
“Markov Perfect Industry Dynamics with Many Firms.” *Econometrica* 76
(6): 1375–1411.

</div>

</div>
